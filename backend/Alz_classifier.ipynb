{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hawd1RhaB_yd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    self.batchnorm1 = nn.BatchNorm2d(num_features=32)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
        "    self.out = nn.Linear(128, 4)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = self.batchnorm1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "zdr48iWfCWz4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"borhanitrash/alzheimer-mri-disease-classification-dataset\")\n",
        "disease_label_from_category = {\n",
        "    0: \"Mild Demented\",\n",
        "    1: \"Moderate Demented\",\n",
        "    2: \"Non Demented\",\n",
        "    3: \"Very Mild Demented\",\n",
        "}"
      ],
      "metadata": {
        "id": "rpXMZDh8PqNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfaac6a-9d9d-473f-bca5-dde9238ae8b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/borhanitrash/alzheimer-mri-disease-classification-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.0M/26.0M [00:00<00:00, 92.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_parquet(f\"{path}/Alzheimer MRI Disease Classification Dataset/Data/train-00000-of-00001-c08a401c53fe5312.parquet\", engine=\"pyarrow\")"
      ],
      "metadata": {
        "id": "pTIfPVJelt6G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_parquet(f\"{path}/Alzheimer MRI Disease Classification Dataset/Data/test-00000-of-00001-44110b9df98c5585.parquet\", engine=\"pyarrow\")"
      ],
      "metadata": {
        "id": "2GRXN1ZNmIKx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vEjJEHckCAsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dict_to_image(image_dict):\n",
        "    if isinstance(image_dict, dict) and 'bytes' in image_dict:\n",
        "        byte_string = image_dict['bytes']\n",
        "        nparr = np.frombuffer(byte_string, np.uint8)\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
        "        return img\n",
        "    else:\n",
        "        raise TypeError(f\"Expected dictionary with 'bytes' key, got {type(image_dict)}\")\n",
        "\n",
        "train_df['img_arr'] = train_df['image'].apply(dict_to_image)\n",
        "train_df.drop(\"image\", axis=1, inplace=True)\n",
        "\n",
        "test_df['img_arr'] = test_df['image'].apply(dict_to_image)\n",
        "test_df.drop(\"image\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "G5u1OEiimUYU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MRIDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = self.df.iloc[idx]['img_arr']\n",
        "    label = self.df.iloc[idx]['label']\n",
        "\n",
        "    image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
        "    label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "train_dataset = MRIDataset(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "xL2Svu2bPobL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, loader, optimizer, num_epochs):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  train_losses = []\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    train_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "  print(\"Finished Training\")\n",
        "  return model, train_losses"
      ],
      "metadata": {
        "id": "1p_EyDNLSkmG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "model, train_losses = train_model(model, train_loader, optimizer, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqk71iyptdRJ",
        "outputId": "69eb0991-d67b-45dc-82a3-b4f60efb193e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Loss: 1.4818\n",
            "Epoch 2/8, Loss: 0.5378\n",
            "Epoch 3/8, Loss: 0.2427\n",
            "Epoch 4/8, Loss: 0.0894\n",
            "Epoch 5/8, Loss: 0.0293\n",
            "Epoch 6/8, Loss: 0.0095\n",
            "Epoch 7/8, Loss: 0.0071\n",
            "Epoch 8/8, Loss: 0.0018\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "NQR1w0NRO5nk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, loader, device):\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  true_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in loader:\n",
        "      images = images.to(device)\n",
        "      outputs = model(images)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      predictions.extend(preds.cpu().numpy())\n",
        "      true_labels.extend(labels.cpu().numpy())\n",
        "  return predictions, true_labels\n",
        "\n",
        "def result_summary(predictions, true_labels):\n",
        "  accuracy = accuracy_score(true_labels, predictions)\n",
        "  print(f\"Accuracy: {accuracy:.4f}\")\n",
        "  conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(conf_matrix)"
      ],
      "metadata": {
        "id": "2hdHGuX3TOxv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, true_labels = predict(model, train_loader, device)\n",
        "result_summary(predictions, true_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dol2z66YPR2P",
        "outputId": "441b7e7e-188b-41d2-f319-f5cba3b1d496"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Confusion Matrix:\n",
            "[[ 724    0    0    0]\n",
            " [   0   49    0    0]\n",
            " [   0    0 2566    0]\n",
            " [   0    0    0 1781]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MRIDataset(test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "predictions_test, test_labels = predict(model, test_loader, device)\n",
        "result_summary(predictions_test, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LeRR_c1QZtZ",
        "outputId": "549276dd-4609-4a3d-fc3c-006d8876c9a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9680\n",
            "Confusion Matrix:\n",
            "[[158   0   7   7]\n",
            " [  0  14   0   1]\n",
            " [  0   0 631   3]\n",
            " [  0   0  23 436]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'alzheimer_cnn.pth')"
      ],
      "metadata": {
        "id": "uK9u5Cf0UBto"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('alzheimer_cnn.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ek_MbiPRYWvH",
        "outputId": "b4ad7492-8635-4b00-9512-0d0fe04e2dc2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_312888af-c2a9-42a0-ba4f-167cbbb34c59\", \"alzheimer_cnn.pth\", 33640149)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}